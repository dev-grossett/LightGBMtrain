% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scoring_function.R
\name{scoring_function}
\alias{scoring_function}
\title{LightGBM training score}
\usage{
scoring_function(
  training_data,
  num_leaves = 2L,
  min_data_in_leaf = 20L,
  num_trees = 4000L,
  learning_rate = 0.01,
  bagging_freq = 1L,
  bagging_fraction = 0.5,
  feature_fraction = 0.6,
  objective = "poisson",
  nfolds = 3L,
  early_stopping_rounds = 100L
)
}
\arguments{
\item{training_data}{Dataset to train model on}

\item{num_leaves}{Maximum number of leaves in one tree}

\item{min_data_in_leaf}{Minimum number of observations one leaf can be based
off}

\item{num_trees}{Number of boosting iterations}

\item{learning_rate}{Shrinkage rate - determines how quickly the ensemble
learns}

\item{bagging_freq}{Frequency for bagging (boostrap aggregation)}

\item{bagging_fraction}{Proportion of data to use for training each tree}

\item{feature_fraction}{Proportion of variables to use for training each tree}

\item{objective}{Loss function - see LightGBM docs for full list available}

\item{nfolds}{number of folds for cross validation score}

\item{early_stopping_rounds}{number of rounds to stop if no improvement in
cross validation score}
}
\value{
List containing the Best Score against the \code{objective} and how many
iterations based on early stopping
}
\description{
Calculates the training score of a LightGBM model using n-fold cross
validation. Useful for tuning hyperparameters
}
